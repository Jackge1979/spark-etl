package com.yxt.bigdata.etl.connector.base.component

import org.apache.spark.sql.{DataFrame, SparkSession}

trait ETLReader {
  /*
  querySql的优先级最高
  若querySql不为空，则忽视columns和where
   */
  val tableName: String

  var columns: Option[Array[String]]

  var where: Option[String]

  val querySql: Option[String]

  def getDataFrame(spark: SparkSession): DataFrame

  def getColumnsFromDataFrame(dataFrame: DataFrame): Array[String] = {
    dataFrame.schema.map(structField => structField.name).toArray
  }
}
