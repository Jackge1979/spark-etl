package com.yxt.bigdata.etl.connector.hive.reader

import com.typesafe.config.Config
import com.yxt.bigdata.etl.connector.base.ETLReader
import org.apache.spark.sql.{DataFrame, SparkSession}


class HiveReader(conf: Config) extends ETLReader {
  override val tableName: String = conf.getString(Key.TABLE_NAME)

  override val columns: Array[String] = {
    val cols = conf.getString(Key.COLUMNS).toLowerCase
    cols.split(",")
  }

  override def getDataFrame(spark: SparkSession, tableName: String): DataFrame = {
    spark.sql("select 1")
  }
}
